
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>botorch.acquisition.monte_carlo &#8212; obsidian  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mycss.css?v=6334c041" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BPMFV2DMZE"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BPMFV2DMZE');
            </script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BPMFV2DMZE');
            </script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/botorch/acquisition/monte_carlo';</script>
    <link rel="icon" href="../../../_static/obsidian_logo.svg"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/obsidian_logo.svg" class="logo__image only-light" alt="obsidian - Home"/>
    <script>document.write(`<img src="../../../_static/obsidian_logo_dark.svg" class="logo__image only-dark" alt="obsidian - Home"/>`);</script>
  
  
    <p class="title logo__title">obsidian APO</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/MSDLLCpapers/obsidian/">
    GitHub
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../stubs/api_docs.html">
    API Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../stubs/wiki.html">
    Wiki
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../stubs/tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../stubs/publications.html">
    Publications
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../../stubs/reference.html">
    Reference
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/MSDLLCpapers/obsidian/" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/obsidian-apo/" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/MSDLLCpapers/obsidian/">
    GitHub
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../stubs/api_docs.html">
    API Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../stubs/wiki.html">
    Wiki
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../stubs/tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../stubs/publications.html">
    Publications
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../stubs/reference.html">
    Reference
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/MSDLLCpapers/obsidian/" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/obsidian-apo/" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">botorch.acqu...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for botorch.acquisition.monte_carlo</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Batch acquisition functions using the reparameterization trick in combination</span>
<span class="sd">with (quasi) Monte-Carlo sampling. See [Rezende2014reparam]_, [Wilson2017reparam]_ and</span>
<span class="sd">[Balandat2020botorch]_.</span>

<span class="sd">References</span>

<span class="sd">.. [Rezende2014reparam]</span>
<span class="sd">    D. J. Rezende, S. Mohamed, and D. Wierstra. Stochastic backpropagation and</span>
<span class="sd">    approximate inference in deep generative models. ICML 2014.</span>

<span class="sd">.. [Wilson2017reparam]</span>
<span class="sd">    J. T. Wilson, R. Moriconi, F. Hutter, and M. P. Deisenroth.</span>
<span class="sd">    The reparameterization trick for acquisition functions. ArXiv 2017.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Protocol</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.acquisition</span><span class="w"> </span><span class="kn">import</span> <span class="n">AcquisitionFunction</span><span class="p">,</span> <span class="n">MCSamplerMixin</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.cached_cholesky</span><span class="w"> </span><span class="kn">import</span> <span class="n">CachedCholeskyMCSamplerMixin</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.objective</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">ConstrainedMCObjective</span><span class="p">,</span>
    <span class="n">IdentityMCObjective</span><span class="p">,</span>
    <span class="n">MCAcquisitionObjective</span><span class="p">,</span>
    <span class="n">PosteriorTransform</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.acquisition.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">compute_best_feasible_objective</span><span class="p">,</span>
    <span class="n">prune_inferior_points</span><span class="p">,</span>
    <span class="n">repeat_to_match_aug_dim</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.exceptions.errors</span><span class="w"> </span><span class="kn">import</span> <span class="n">UnsupportedError</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.exceptions.warnings</span><span class="w"> </span><span class="kn">import</span> <span class="n">legacy_ei_numerics_warning</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.models.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.sampling.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">MCSampler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.objective</span><span class="w"> </span><span class="kn">import</span> <span class="n">compute_smoothed_feasibility_indicator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">botorch.utils.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">concatenate_pending_points</span><span class="p">,</span>
    <span class="n">match_batch_shape</span><span class="p">,</span>
    <span class="n">t_batch_mode_transform</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span>


<span class="k">class</span><span class="w"> </span><span class="nc">MCAcquisitionFunction</span><span class="p">(</span><span class="n">AcquisitionFunction</span><span class="p">,</span> <span class="n">MCSamplerMixin</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract base class for Monte-Carlo based batch acquisition functions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            sampler: The sampler used to draw base samples. If not given,</span>
<span class="sd">                a sampler is generated on the fly within the</span>
<span class="sd">                `get_posterior_samples` method using</span>
<span class="sd">                `botorch.sampling.get_sampler`.</span>
<span class="sd">                NOTE: For posteriors that do not support base samples,</span>
<span class="sd">                a sampler compatible with intended use case must be provided.</span>
<span class="sd">                See `ForkedRNGSampler` and `StochasticSampler` as examples.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending: A `batch_shape, m x d`-dim Tensor of `m` design points</span>
<span class="sd">                that have points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
        <span class="n">MCSamplerMixin</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">objective</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">model</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">posterior_transform</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                    <span class="s2">&quot;Must specify an objective or a posterior transform when using &quot;</span>
                    <span class="s2">&quot;a multi-output model.&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="n">posterior_transform</span><span class="o">.</span><span class="n">scalarize</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                    <span class="s2">&quot;If using a multi-output model without an objective, &quot;</span>
                    <span class="s2">&quot;posterior_transform must scalarize the output.&quot;</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">objective</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="n">IdentityMCObjective</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span> <span class="o">=</span> <span class="n">posterior_transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">:</span> <span class="n">MCAcquisitionObjective</span> <span class="o">=</span> <span class="n">objective</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_X_pending</span><span class="p">(</span><span class="n">X_pending</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_samples_and_objectives</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes posterior samples and objective values at input X.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x q x d`-dim Tensor of model inputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple `(samples, obj)`, where `samples` is a tensor of posterior</span>
<span class="sd">            samples with shape `sample_shape x batch_shape x q x m`, and `obj` is a</span>
<span class="sd">            tensor of MC objective values with shape `sample_shape x batch_shape x q`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span>
        <span class="p">)</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_posterior_samples</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="n">obj</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Takes in a `batch_shape x q x d` X Tensor of t-batches with `q` `d`-dim</span>
<span class="sd">        design points each, and returns a Tensor with shape `batch_shape&#39;`, where</span>
<span class="sd">        `batch_shape&#39;` is the broadcasted batch shape of model and input `X`. Should</span>
<span class="sd">        utilize the result of `set_X_pending` as needed to account for pending function</span>
<span class="sd">        evaluations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span>


<span class="k">class</span><span class="w"> </span><span class="nc">SampleReductionProtocol</span><span class="p">(</span><span class="n">Protocol</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;For static type check of SampleReducingMCAcquisitionFunction&#39;s mc_reduction.&quot;&quot;&quot;</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span>


<span class="k">class</span><span class="w"> </span><span class="nc">SampleReducingMCAcquisitionFunction</span><span class="p">(</span><span class="n">MCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;MC-based batch acquisition function that reduces across samples and implements</span>
<span class="sd">    a general treatment of outcome constraints.</span>

<span class="sd">    This class&#39;s `forward` computes the - possibly constrained - acquisition value by</span>
<span class="sd">    (1) computing the unconstrained utility for each MC sample using `_sample_forward`,</span>
<span class="sd">    (2) weighing the utility values by the constraint indicator per MC sample, and</span>
<span class="sd">    (3) reducing (e.g. averaging) the weighted utility values over the MC dimension.</span>

<span class="sd">    NOTE: Do *NOT* override the `forward` method, unless you have thought about it well.</span>

<span class="sd">    `forward` is implemented generically to incorporate constraints in a principled way,</span>
<span class="sd">    and takes care of reducing over the Monte Carlo and batch dimensions via the</span>
<span class="sd">    `sample_reduction` and `q_reduction` arguments, which default to `torch.mean` and</span>
<span class="sd">    `torch.max`, respectively.</span>

<span class="sd">    In order to implement a custom SampleReducingMCAcquisitionFunction, we only need to</span>
<span class="sd">    implement the `_sample_forward(obj: Tensor) -&gt; Tensor` method, which maps objective</span>
<span class="sd">    samples to acquisition utility values without reducing the Monte Carlo and batch</span>
<span class="sd">    (i.e. q) dimensions (see details in the docstring of `_sample_forward`).</span>

<span class="sd">    A note on design choices:</span>

<span class="sd">    The primary purpose of `SampleReducingMCAcquisitionFunction`is to support outcome</span>
<span class="sd">    constraints. On the surface, designing a wrapper `ConstrainedMCAcquisitionFunction`</span>
<span class="sd">    could be an elegant solution to this end, but it would still require the acquisition</span>
<span class="sd">    functions to implement a `_sample_forward` method to weigh acquisition utilities at</span>
<span class="sd">    the sample level. Further, `qNoisyExpectedImprovement` is a special case that is</span>
<span class="sd">    hard to encompass in this pattern, since it requires the computation of the best</span>
<span class="sd">    *feasible* objective, which requires access to the constraint functions. However,</span>
<span class="sd">    if the constraints are stored in a wrapper class, they will be inaccessible to the</span>
<span class="sd">    forward pass. These problems are circumvented by the design of this class.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_log</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># whether the acquisition utilities are in log-space</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sample_reduction</span><span class="p">:</span> <span class="n">SampleReductionProtocol</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span>
        <span class="n">q_reduction</span><span class="p">:</span> <span class="n">SampleReductionProtocol</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">amax</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">fat</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Constructor of SampleReducingMCAcquisitionFunction.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            sampler: The sampler used to draw base samples. If not given, a</span>
<span class="sd">                sampler is generated on the fly within the</span>
<span class="sd">                `get_posterior_samples` method using</span>
<span class="sd">                `botorch.sampling.get_sampler`.</span>
<span class="sd">                NOTE: For posteriors that do not support base samples,</span>
<span class="sd">                a sampler compatible with intended use case must be provided.</span>
<span class="sd">                See `ForkedRNGSampler` and `StochasticSampler` as examples.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">                NOTE: `ConstrainedMCObjective` for outcome constraints is deprecated in</span>
<span class="sd">                favor of passing the `constraints` directly to this constructor.</span>
<span class="sd">            posterior_transform: A `PosteriorTransform` (optional).</span>
<span class="sd">            X_pending: A `batch_shape, m x d`-dim Tensor of `m` design points</span>
<span class="sd">                that have points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated.</span>
<span class="sd">            sample_reduction: A callable that takes in a `sample_shape x batch_shape`</span>
<span class="sd">                Tensor of acquisition utility values, a keyword-argument `dim` that</span>
<span class="sd">                specifies the sample dimensions to reduce over, and returns a</span>
<span class="sd">                `batch_shape`-dim Tensor of acquisition values.</span>
<span class="sd">            q_reduction: A callable that takes in a `sample_shape x batch_shape x q`</span>
<span class="sd">                Tensor of acquisition utility values, a keyword-argument `dim` that</span>
<span class="sd">                specifies the q dimension to reduce over (i.e. -1), and returns a</span>
<span class="sd">                `sample_shape x batch_shape`-dim Tensor of acquisition values.</span>
<span class="sd">            constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">                samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">                are considered satisfied if the output is less than zero.</span>
<span class="sd">                NOTE: Constraint-weighting is only compatible with non-negative</span>
<span class="sd">                acquistion utilities, e.g. all improvement-based acquisition functions.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. For more details, on this</span>
<span class="sd">                parameter, see the docs of `compute_smoothed_feasibility_indicator`.</span>
<span class="sd">            fat: Wether to apply a fat-tailed smooth approximation to the feasibility</span>
<span class="sd">                indicator or the canonical sigmoid approximation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">constraints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">ConstrainedMCObjective</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;ConstrainedMCObjective as well as constraints passed to constructor.&quot;</span>
                <span class="s2">&quot;Choose one or the other, preferably the latter.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># TODO: deprecate ConstrainedMCObjective</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Shall the need arise, sample_dim could be exposed in the constructor.</span>
        <span class="n">sample_dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_shape</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sample_reduction</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">sample_reduction</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">sample_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_q_reduction</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">q_reduction</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span> <span class="o">=</span> <span class="n">constraints</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_eta</span> <span class="o">=</span> <span class="n">eta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fat</span> <span class="o">=</span> <span class="n">fat</span>

    <span class="nd">@concatenate_pending_points</span>
    <span class="nd">@t_batch_mode_transform</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the acquisition value associated with the input `X`. Weighs the</span>
<span class="sd">        acquisition utility values by smoothed constraint indicators if `constraints`</span>
<span class="sd">        was passed to the constructor of the class. Applies `self.sample_reduction` and</span>
<span class="sd">        `self.q_reduction` to reduce over the Monte Carlo and batch (q) dimensions.</span>

<span class="sd">        NOTE: Do *NOT* override the `forward` method for a custom acquisition function.</span>
<span class="sd">        Instead, implement the `_sample_forward` method. See the docstring of this class</span>
<span class="sd">        for details.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x q x d` Tensor of t-batches with `q` `d`-dim</span>
<span class="sd">                design points each.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Tensor with shape `batch_shape&#39;`, where `batch_shape&#39;` is the broadcasted</span>
<span class="sd">            batch shape of model and input `X`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">non_reduced_acqval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_reduced_forward</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_reduction</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_q_reduction</span><span class="p">(</span><span class="n">non_reduced_acqval</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_non_reduced_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the constrained acquisition values at the MC-sample, q level.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x q x d` Tensor of t-batches with `q` `d`-dim</span>
<span class="sd">                design points each.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Tensor with shape `sample_sample x batch_shape x q`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">samples</span><span class="p">,</span> <span class="n">obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_samples_and_objectives</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">repeat_to_match_aug_dim</span><span class="p">(</span><span class="n">target_tensor</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span> <span class="n">reference_tensor</span><span class="o">=</span><span class="n">obj</span><span class="p">)</span>
        <span class="n">acqval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_forward</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>  <span class="c1"># `sample_sample x batch_shape x q`</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_constraints</span><span class="p">(</span><span class="n">acqval</span><span class="o">=</span><span class="n">acqval</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">)</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluates the acquisition utility per MC sample based on objective value obj.</span>
<span class="sd">        Should utilize the result of `set_X_pending` as needed to account for pending</span>
<span class="sd">        function evaluations.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of acquisition utility values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_apply_constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">acqval</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Multiplies the acquisition utility by constraint indicators.</span>

<span class="sd">        Args:</span>
<span class="sd">            acqval: `sample_shape x batch_shape x q`-dim acquisition utility values.</span>
<span class="sd">            samples: `sample_shape x batch_shape x q x m`-dim posterior samples.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of acquisition utility values</span>
<span class="sd">                multiplied by a smoothed constraint indicator per sample.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log</span> <span class="ow">and</span> <span class="p">(</span><span class="n">acqval</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Constraint-weighting requires unconstrained &quot;</span>
                    <span class="s2">&quot;acquisition values to be non-negative.&quot;</span>
                <span class="p">)</span>
            <span class="n">ind</span> <span class="o">=</span> <span class="n">compute_smoothed_feasibility_indicator</span><span class="p">(</span>
                <span class="n">constraints</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">,</span>
                <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
                <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_eta</span><span class="p">,</span>
                <span class="n">log</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_log</span><span class="p">,</span>
                <span class="n">fat</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_fat</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">acqval</span> <span class="o">=</span> <span class="n">acqval</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log</span> <span class="k">else</span> <span class="n">acqval</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">acqval</span>


<span class="k">class</span><span class="w"> </span><span class="nc">qExpectedImprovement</span><span class="p">(</span><span class="n">SampleReducingMCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;MC-based batch Expected Improvement.</span>

<span class="sd">    This computes qEI by</span>
<span class="sd">    (1) sampling the joint posterior over q points</span>
<span class="sd">    (2) evaluating the improvement over the current best for each sample</span>
<span class="sd">    (3) maximizing over q</span>
<span class="sd">    (4) averaging over the samples</span>

<span class="sd">    `qEI(X) = E(max(max Y - best_f, 0)), Y ~ f(X), where X = (x_1,...,x_q)`</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; best_f = train_Y.max()[0]</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qEI = qExpectedImprovement(model, best_f, sampler)</span>
<span class="sd">        &gt;&gt;&gt; qei = qEI(test_X)</span>

<span class="sd">    NOTE: It is strongly recommended to use qLogExpectedImprovement instead</span>
<span class="sd">    of regular qEI, as it can lead to substantially improved BO performance through</span>
<span class="sd">    improved numerics. See https://arxiv.org/abs/2310.20708 for details.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">best_f</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;q-Expected Improvement.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            best_f: The best objective value observed so far (assumed noiseless). Can be</span>
<span class="sd">                a scalar, or a `batch_shape`-dim tensor. In case of a batched model, the</span>
<span class="sd">                tensor can specify different values for each element of the batch.</span>
<span class="sd">            sampler: The sampler used to draw base samples. See `MCAcquisitionFunction`</span>
<span class="sd">                more details.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are evaluated.</span>
<span class="sd">                Defaults to `IdentityMCObjective()`.</span>
<span class="sd">                NOTE: `ConstrainedMCObjective` for outcome constraints is deprecated in</span>
<span class="sd">                favor of passing the `constraints` directly to this constructor.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending:  A `m x d`-dim Tensor of `m` design points that have been</span>
<span class="sd">                submitted for function evaluation but have not yet been evaluated.</span>
<span class="sd">                Concatenated into X upon forward call. Copied and set to have no</span>
<span class="sd">                gradient.</span>
<span class="sd">            constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">                samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">                are considered satisfied if the output is less than zero.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. For more details, on this</span>
<span class="sd">                parameter, see the docs of `compute_smoothed_feasibility_indicator`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">legacy_ei_numerics_warning</span><span class="p">(</span><span class="n">legacy_name</span><span class="o">=</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;best_f&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">best_f</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate qExpectedImprovement per sample on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of improvement utility values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">obj</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_f</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">qNoisyExpectedImprovement</span><span class="p">(</span>
    <span class="n">SampleReducingMCAcquisitionFunction</span><span class="p">,</span> <span class="n">CachedCholeskyMCSamplerMixin</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;MC-based batch Noisy Expected Improvement.</span>

<span class="sd">    This function does not assume a `best_f` is known (which would require</span>
<span class="sd">    noiseless observations). Instead, it uses samples from the joint posterior</span>
<span class="sd">    over the `q` test points and previously observed points. The improvement</span>
<span class="sd">    over previously observed points is computed for each sample and averaged.</span>

<span class="sd">    `qNEI(X) = E(max(max Y - max Y_baseline, 0))`, where</span>
<span class="sd">    `(Y, Y_baseline) ~ f((X, X_baseline)), X = (x_1,...,x_q)`</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qNEI = qNoisyExpectedImprovement(model, train_X, sampler)</span>
<span class="sd">        &gt;&gt;&gt; qnei = qNEI(test_X)</span>

<span class="sd">    NOTE: It is strongly recommended to use qLogNoisyExpectedImprovement instead</span>
<span class="sd">    of regular qNEI, as it can lead to substantially improved BO performance through</span>
<span class="sd">    improved numerics. See https://arxiv.org/abs/2310.20708 for details.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">X_baseline</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prune_baseline</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">cache_root</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">marginalize_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;q-Noisy Expected Improvement.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            X_baseline: A `batch_shape x r x d`-dim Tensor of `r` design points</span>
<span class="sd">                that have already been observed. These points are considered as</span>
<span class="sd">                the potential best design point.</span>
<span class="sd">            sampler: The sampler used to draw base samples. See `MCAcquisitionFunction`</span>
<span class="sd">                more details.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">                NOTE: `ConstrainedMCObjective` for outcome constraints is deprecated in</span>
<span class="sd">                favor of passing the `constraints` directly to this constructor.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending: A `batch_shape x m x d`-dim Tensor of `m` design points</span>
<span class="sd">                that have points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated. Concatenated into `X` upon</span>
<span class="sd">                forward call. Copied and set to have no gradient.</span>
<span class="sd">            prune_baseline: If True, remove points in `X_baseline` that are</span>
<span class="sd">                highly unlikely to be the best point. This can significantly</span>
<span class="sd">                improve performance and is generally recommended. In order to</span>
<span class="sd">                customize pruning parameters, instead manually call</span>
<span class="sd">                `botorch.acquisition.utils.prune_inferior_points` on `X_baseline`</span>
<span class="sd">                before instantiating the acquisition function.</span>
<span class="sd">            cache_root: A boolean indicating whether to cache the root</span>
<span class="sd">                decomposition over `X_baseline` and use low-rank updates.</span>
<span class="sd">            constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">                samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">                `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">                are considered satisfied if the output is less than zero.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. For more details, on this</span>
<span class="sd">                parameter, see the docs of `compute_smoothed_feasibility_indicator`.</span>
<span class="sd">            marginalize_dim: The dimension to marginalize over.</span>

<span class="sd">        TODO: similar to qNEHVI, when we are using sequential greedy candidate</span>
<span class="sd">        selection, we could incorporate pending points X_baseline and compute</span>
<span class="sd">        the incremental qNEI from the new point. This would greatly increase</span>
<span class="sd">        efficiency for large batches.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">legacy_ei_numerics_warning</span><span class="p">(</span><span class="n">legacy_name</span><span class="o">=</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">CachedCholeskyMCSamplerMixin</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">cache_root</span><span class="o">=</span><span class="n">cache_root</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">prune_baseline</span><span class="p">:</span>
            <span class="n">X_baseline</span> <span class="o">=</span> <span class="n">prune_inferior_points</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X_baseline</span><span class="p">,</span>
                <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
                <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
                <span class="n">constraints</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">,</span>
                <span class="n">marginalize_dim</span><span class="o">=</span><span class="n">marginalize_dim</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;X_baseline&quot;</span><span class="p">,</span> <span class="n">X_baseline</span><span class="p">)</span>
        <span class="c1"># registering buffers for _get_samples_and_objectives in the next `if` block</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;baseline_samples&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;baseline_obj&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_root</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">q_in</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="c1"># set baseline samples</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># this is _get_samples_and_objectives(X_baseline)</span>
                <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
                    <span class="n">X_baseline</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span>
                <span class="p">)</span>
                <span class="c1"># Note: The root decomposition is cached in two different places. It</span>
                <span class="c1"># may be confusing to have two different caches, but this is not</span>
                <span class="c1"># trivial to change since each is needed for a different reason:</span>
                <span class="c1"># - LinearOperator caching to `posterior.mvn` allows for reuse within</span>
                <span class="c1">#  this function, which may be helpful if the same root decomposition</span>
                <span class="c1">#  is produced by the calls to `self.base_sampler` and</span>
                <span class="c1">#  `self._cache_root_decomposition`.</span>
                <span class="c1"># - self._baseline_L allows a root decomposition to be persisted outside</span>
                <span class="c1">#   this method.</span>
                <span class="n">baseline_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_posterior_samples</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
                <span class="n">baseline_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_baseline</span><span class="p">)</span>

            <span class="c1"># We make a copy here because we will write an attribute `base_samples`</span>
            <span class="c1"># to `self.base_sampler.base_samples`, and we don&#39;t want to mutate</span>
            <span class="c1"># `self.sampler`.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_sampler</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span> <span class="o">=</span> <span class="n">baseline_samples</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span> <span class="o">=</span> <span class="n">baseline_obj</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;_baseline_best_f&quot;</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_compute_best_feasible_objective</span><span class="p">(</span>
                    <span class="n">samples</span><span class="o">=</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="n">baseline_obj</span>
                <span class="p">),</span>  <span class="c1"># `sample_shape x batch_shape`-dim</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_L</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_root_decomposition</span><span class="p">(</span><span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_best_f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the best (feasible) noisy objective value.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: `sample_shape x batch_shape x q`-dim Tensor of objectives in forward.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape`-dim Tensor of best feasible objectives.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_root</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_best_f</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_best_feasible_objective</span><span class="p">(</span>
                <span class="n">samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span>
            <span class="p">)</span>
        <span class="c1"># ensuring shape, dtype, device compatibility with obj</span>
        <span class="n">n_sample_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_shape</span><span class="p">)</span>
        <span class="n">view_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="o">*</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">n_sample_dims</span><span class="p">],</span>  <span class="c1"># sample dimensions</span>
                <span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="n">val</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>  <span class="c1"># pad to match obj, without `q`-dim</span>
                <span class="o">*</span><span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">n_sample_dims</span><span class="p">:],</span>  <span class="c1"># the rest</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">val</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">view_shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>  <span class="c1"># obj.shape[:-1], i.e. without `q`-dim`</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate qNoisyExpectedImprovement per objective value in `obj`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of noisy improvement values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">obj</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_best_f</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_samples_and_objectives</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute samples at new points, using the cached root decomposition.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x q x d`-dim tensor of inputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A two-tuple `(samples, obj)`, where `samples` is a tensor of posterior</span>
<span class="sd">            samples with shape `sample_shape x batch_shape x q x m`, and `obj` is a</span>
<span class="sd">            tensor of MC objective values with shape `sample_shape x batch_shape x q`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">X_full</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">match_batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_baseline</span><span class="p">,</span> <span class="n">X</span><span class="p">),</span> <span class="n">X</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
        <span class="c1"># TODO: Implement more efficient way to compute posterior over both training and</span>
        <span class="c1"># test points in GPyTorch (https://github.com/cornellius-gp/gpytorch/issues/567)</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
            <span class="n">X_full</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_root</span><span class="p">:</span>
            <span class="n">samples_full</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_posterior_samples</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="n">samples_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">q</span><span class="p">:,</span> <span class="p">:]</span>
            <span class="n">obj_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">samples_full</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_full</span><span class="p">)</span>
            <span class="c1"># assigning baseline buffers so `best_f` can be computed in _sample_forward</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">baseline_obj</span><span class="p">,</span> <span class="n">obj</span> <span class="o">=</span> <span class="n">obj_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="n">q</span><span class="p">],</span> <span class="n">obj_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">q</span><span class="p">:]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">baseline_samples</span> <span class="o">=</span> <span class="n">samples_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="n">q</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># handle one-to-many input transforms</span>
            <span class="n">n_plus_q</span> <span class="o">=</span> <span class="n">X_full</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">n_w</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">_extended_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="n">n_plus_q</span>
            <span class="n">q_in</span> <span class="o">=</span> <span class="n">q</span> <span class="o">*</span> <span class="n">n_w</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set_sampler</span><span class="p">(</span><span class="n">q_in</span><span class="o">=</span><span class="n">q_in</span><span class="p">,</span> <span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">)</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_f_X_samples</span><span class="p">(</span><span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span> <span class="n">q_in</span><span class="o">=</span><span class="n">q_in</span><span class="p">)</span>
            <span class="n">obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_full</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">q</span><span class="p">:,</span> <span class="p">:])</span>

        <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="n">obj</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_best_feasible_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes best feasible objective value from samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            samples: `sample_shape x batch_shape x q x m`-dim posterior samples.</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape`-dim Tensor of best feasible objectives.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">compute_best_feasible_objective</span><span class="p">(</span>
            <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
            <span class="n">obj</span><span class="o">=</span><span class="n">obj</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_baseline</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_baseline</span><span class="p">,</span>
        <span class="p">)</span>


<div class="viewcode-block" id="qProbabilityOfImprovement">
<a class="viewcode-back" href="../../../build/apidocs/obsidian.acquisition.botorch.html#obsidian.acquisition.botorch.qProbabilityOfImprovement">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">qProbabilityOfImprovement</span><span class="p">(</span><span class="n">SampleReducingMCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;MC-based batch Probability of Improvement.</span>

<span class="sd">    Estimates the probability of improvement over the current best observed</span>
<span class="sd">    value by sampling from the joint posterior distribution of the q-batch.</span>
<span class="sd">    MC-based estimates of a probability involves taking expectation of an</span>
<span class="sd">    indicator function; to support auto-differentiation, the indicator is</span>
<span class="sd">    replaced with a sigmoid function with temperature parameter `tau`.</span>

<span class="sd">    `qPI(X) = P(max Y &gt;= best_f), Y ~ f(X), X = (x_1,...,x_q)`</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; best_f = train_Y.max()[0]</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qPI = qProbabilityOfImprovement(model, best_f, sampler)</span>
<span class="sd">        &gt;&gt;&gt; qpi = qPI(test_X)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">best_f</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tau</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;q-Probability of Improvement.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            best_f: The best objective value observed so far (assumed noiseless). Can</span>
<span class="sd">                be a `batch_shape`-shaped tensor, which in case of a batched model</span>
<span class="sd">                specifies potentially different values for each element of the batch.</span>
<span class="sd">            sampler: The sampler used to draw base samples. See `MCAcquisitionFunction`</span>
<span class="sd">                more details.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">                NOTE: `ConstrainedMCObjective` for outcome constraints is deprecated in</span>
<span class="sd">                favor of passing the `constraints` directly to this constructor.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending:  A `m x d`-dim Tensor of `m` design points that have</span>
<span class="sd">                points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated.  Concatenated into X upon</span>
<span class="sd">                forward call.  Copied and set to have no gradient.</span>
<span class="sd">            tau: The temperature parameter used in the sigmoid approximation</span>
<span class="sd">                of the step function. Smaller values yield more accurate</span>
<span class="sd">                approximations of the function, but result in gradients</span>
<span class="sd">                estimates with higher variance.</span>
<span class="sd">            constraints: A list of constraint callables which map posterior samples to</span>
<span class="sd">                a scalar. The associated constraint is considered satisfied if this</span>
<span class="sd">                scalar is less than zero.</span>
<span class="sd">            eta: Temperature parameter(s) governing the smoothness of the sigmoid</span>
<span class="sd">                approximation to the constraint indicators. For more details, on this</span>
<span class="sd">                parameter, see the docs of `compute_smoothed_feasibility_indicator`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
            <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
            <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">best_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">best_f</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># adding batch dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;best_f&quot;</span><span class="p">,</span> <span class="n">best_f</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;tau&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate qProbabilityOfImprovement per sample on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of improvement indicators.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">improvement</span> <span class="o">=</span> <span class="n">obj</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_f</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">improvement</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">)</span></div>



<div class="viewcode-block" id="qSimpleRegret">
<a class="viewcode-back" href="../../../build/apidocs/obsidian.acquisition.botorch.html#obsidian.acquisition.botorch.qSimpleRegret">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">qSimpleRegret</span><span class="p">(</span><span class="n">SampleReducingMCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;MC-based batch Simple Regret.</span>

<span class="sd">    Samples from the joint posterior over the q-batch and computes the simple regret.</span>

<span class="sd">    `qSR(X) = E(max Y), Y ~ f(X), X = (x_1,...,x_q)`</span>

<span class="sd">    Constraints should be provided as a `ConstrainedMCObjective`.</span>
<span class="sd">    Passing `constraints` as an argument is not supported. This is because</span>
<span class="sd">    `SampleReducingMCAcquisitionFunction` computes the acquisition values on the sample</span>
<span class="sd">    level and then weights the sample-level acquisition values by a soft feasibility</span>
<span class="sd">    indicator. Hence, it expects non-log acquisition function values to be</span>
<span class="sd">    non-negative. `qSimpleRegret` acquisition values can be negative, so we instead use</span>
<span class="sd">    a `ConstrainedMCObjective` which applies constraints to the objectives (e.g. before</span>
<span class="sd">    computing the acquisition function) and shifts negative objective values using</span>
<span class="sd">    by an infeasible cost to ensure non-negativity (before applying constraints and</span>
<span class="sd">    shifting them back).</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qSR = qSimpleRegret(model, sampler)</span>
<span class="sd">        &gt;&gt;&gt; qsr = qSR(test_X)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;q-Simple Regret.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            sampler: The sampler used to draw base samples. See `MCAcquisitionFunction`</span>
<span class="sd">                more details.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending:  A `m x d`-dim Tensor of `m` design points that have</span>
<span class="sd">                points that have been submitted for function evaluation</span>
<span class="sd">                but have not yet been evaluated.  Concatenated into X upon</span>
<span class="sd">                forward call.  Copied and set to have no gradient.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate qSimpleRegret per sample on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of simple regret values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">obj</span></div>



<div class="viewcode-block" id="qUpperConfidenceBound">
<a class="viewcode-back" href="../../../build/apidocs/obsidian.acquisition.botorch.html#obsidian.acquisition.botorch.qUpperConfidenceBound">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">qUpperConfidenceBound</span><span class="p">(</span><span class="n">SampleReducingMCAcquisitionFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;MC-based batch Upper Confidence Bound.</span>

<span class="sd">    Uses a reparameterization to extend UCB to qUCB for q &gt; 1 (See Appendix A</span>
<span class="sd">    of [Wilson2017reparam].)</span>

<span class="sd">    `qUCB = E(max(mu + |Y_tilde - mu|))`, where `Y_tilde ~ N(mu, beta pi/2 Sigma)`</span>
<span class="sd">    and `f(X)` has distribution `N(mu, Sigma)`.</span>

<span class="sd">    Constraints should be provided as a `ConstrainedMCObjective`.</span>
<span class="sd">    Passing `constraints` as an argument is not supported. This is because</span>
<span class="sd">    `SampleReducingMCAcquisitionFunction` computes the acquisition values on the sample</span>
<span class="sd">    level and then weights the sample-level acquisition values by a soft feasibility</span>
<span class="sd">    indicator. Hence, it expects non-log acquisition function values to be</span>
<span class="sd">    non-negative. `qSimpleRegret` acquisition values can be negative, so we instead use</span>
<span class="sd">    a `ConstrainedMCObjective` which applies constraints to the objectives (e.g. before</span>
<span class="sd">    computing the acquisition function) and shifts negative objective values using</span>
<span class="sd">    by an infeasible cost to ensure non-negativity (before applying constraints and</span>
<span class="sd">    shifting them back).</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; sampler = SobolQMCNormalSampler(1024)</span>
<span class="sd">        &gt;&gt;&gt; qUCB = qUpperConfidenceBound(model, 0.1, sampler)</span>
<span class="sd">        &gt;&gt;&gt; qucb = qUCB(test_X)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
        <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">X_pending</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;q-Upper Confidence Bound.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: A fitted model.</span>
<span class="sd">            beta: Controls tradeoff between mean and standard deviation in UCB.</span>
<span class="sd">            sampler: The sampler used to draw base samples. See `MCAcquisitionFunction`</span>
<span class="sd">                more details.</span>
<span class="sd">            objective: The MCAcquisitionObjective under which the samples are</span>
<span class="sd">                evaluated. Defaults to `IdentityMCObjective()`.</span>
<span class="sd">            posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">            X_pending: A `batch_shape x m x d`-dim Tensor of `m` design points that have</span>
<span class="sd">                points that have been submitted for function evaluation but have not yet</span>
<span class="sd">                been evaluated. Concatenated into X upon forward call. Copied and set to</span>
<span class="sd">                have no gradient.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X_pending</span><span class="o">=</span><span class="n">X_pending</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta_prime</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">beta</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_sample_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Evaluate qUpperConfidenceBound per sample on the candidate set `X`.</span>

<span class="sd">        Args:</span>
<span class="sd">            obj: A `sample_shape x batch_shape x q`-dim Tensor of MC objective values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `sample_shape x batch_shape x q`-dim Tensor of acquisition values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta_prime</span> <span class="o">*</span> <span class="p">(</span><span class="n">obj</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span></div>

</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright Merck &amp; Co., Inc., Rahway, NJ, USA and its affiliates. All rights reserved..
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>